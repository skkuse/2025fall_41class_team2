# llm_project/api/rag_utils.py

import os
from dotenv import load_dotenv
import chromadb
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader
from langchain_openai import OpenAIEmbeddings
from langchain_openai import ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (OPENAI_API_KEY)
load_dotenv()

# --- ChromaDB í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ë¡œì»¬ ì˜êµ¬ ì €ì¥) ---
CHROMA_PERSIST_DIR = "chroma_db"
chroma_client = chromadb.PersistentClient(path=CHROMA_PERSIST_DIR)

# --- OpenAI ì„ë² ë”© ëª¨ë¸ ---
openai_embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",
    api_key=os.getenv("OPENAI_API_KEY")
)

# --- OpenAI LLM (ì±—ë´‡ ëª¨ë¸) ---
llm = ChatOpenAI(
    model="gpt-4o",
    api_key=os.getenv("OPENAI_API_KEY"),
    temperature=0.0  # ë‹µë³€ì˜ ì¼ê´€ì„±ì„ ìœ„í•´ 0.0ìœ¼ë¡œ ì„¤ì •
)

# --- í…ìŠ¤íŠ¸ ë¶„í• ê¸° ---
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)

def process_and_index_pdf(document_id):
    """
    Document IDë¥¼ ë°›ì•„ PDFë¥¼ ë¡œë“œ, ë¶„í• , ì„ë² ë”©í•˜ê³  ChromaDBì— ì €ì¥
    ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•´ document_idë¥¼ ì¸ìë¡œ ë°›ìŒ
    """
    try:
        from .models import Document, DocumentPage  # Avoid circular import
        
        # ìµœì‹  ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
        document_obj = Document.objects.get(id=document_id)
        
        file_path = document_obj.file.path
        project_id = str(document_obj.project.id)
        document_id = str(document_obj.id)

        # ìƒíƒœ ì—…ë°ì´íŠ¸: ì‹œì‘
        document_obj.status = 'processing'
        document_obj.processing_message = "Starting PDF processing..."
        document_obj.save()

        # [ì „ëµ] í”„ë¡œì íŠ¸ IDë³„ë¡œ ë³„ë„ì˜ ì»¬ë ‰ì…˜(í…Œì´ë¸”)ì„ ì‚¬ìš©
        collection_name = f"project_{project_id}"
        collection = chroma_client.get_or_create_collection(name=collection_name)

        # 1. PDF ë¶ˆëŸ¬ì˜¤ê¸° (Load)
        document_obj.processing_message = "Loading PDF..."
        document_obj.save()
        
        loader = PyPDFLoader(file_path)
        docs = loader.load()

        # --- í˜ì´ì§€ë³„ ì›ë¬¸ ì €ì¥ ë° ë²ˆì—­ ---
        print(f"ğŸ“„ [Doc: {document_id}] {len(docs)} í˜ì´ì§€ ì²˜ë¦¬ ë° ë²ˆì—­ ì‹œì‘...")
        
        # ë²ˆì—­ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
        translation_prompt = ChatPromptTemplate.from_template(
            """
            Translate the following English text into Korean.
            Maintain the original tone and formatting as much as possible.
            Only return the translated text.
            
            Text:
            {text}
            """
        )
        translation_chain = translation_prompt | llm | StrOutputParser()

        total_pages = len(docs)
        for i, doc in enumerate(docs):
            page_num = doc.metadata.get('page', 0) + 1
            
            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
            document_obj.processing_message = f"Translating page {page_num} of {total_pages}..."
            document_obj.save()
            
            original_text = doc.page_content
            
            # ë²ˆì—­ ì‹¤í–‰
            try:
                translated_text = translation_chain.invoke({"text": original_text})
            except Exception as e:
                print(f"âš ï¸ [Page {page_num}] ë²ˆì—­ ì‹¤íŒ¨: {e}")
                translated_text = ""

            # DB ì €ì¥
            DocumentPage.objects.create(
                document=document_obj,
                page_number=page_num,
                original_text=original_text,
                translated_text=translated_text
            )
            print(f"   - Page {page_num} ì €ì¥ ì™„ë£Œ")

        # 2. í…ìŠ¤íŠ¸ ë¶„í•  (Split) - RAGìš©
        document_obj.processing_message = "Indexing documents..."
        document_obj.save()
        
        split_docs = text_splitter.split_documents(docs)

        documents_to_add = []
        metadatas_to_add = []
        ids_to_add = []  # ê° ì¡°ê°ì˜ ê³ ìœ  ID

        for i, doc in enumerate(split_docs):
            documents_to_add.append(doc.page_content)
            
            # [í•µì‹¬] ê¼¬ë¦¬í‘œ(ë©”íƒ€ë°ì´í„°)ì— document_idë¥¼ í¬í•¨
            metadatas_to_add.append({
                "document_id": document_id,
                "source_page": doc.metadata.get('page', 0),
                "name": document_obj.name
            })
            
            # [í•µì‹¬] ì‚­ì œ ë° ê´€ë¦¬ë¥¼ ìœ„í•œ ê³ ìœ  ID
            ids_to_add.append(f"doc_{document_id}_chunk_{i}")

        if documents_to_add:
            embeddings_to_add = openai_embeddings.embed_documents(documents_to_add)
            collection.add(
                embeddings=embeddings_to_add,
                documents=documents_to_add,
                metadatas=metadatas_to_add,
                ids=ids_to_add
            )
        
        print(f"âœ… [Project: {project_id}, Doc: {document_id}] ì¸ë±ì‹± ë° ë²ˆì—­ ì €ì¥ ì„±ê³µ. {len(ids_to_add)}ê°œ ë²¡í„° ì¶”ê°€.")
        
        # ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸
        document_obj.status = 'processed'
        document_obj.processing_message = "Completed"
        document_obj.save()
        return True

    except Exception as e:
        print(f"âŒ [Project: {project_id}, Doc: {document_id}] ì¸ë±ì‹± ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨ ìƒíƒœ ì—…ë°ì´íŠ¸
        try:
            document_obj = Document.objects.get(id=document_id)
            document_obj.status = 'failed'
            document_obj.processing_message = f"Error: {str(e)}"
            document_obj.save()
        except:
            pass
        return False

def remove_document_vectors(document_obj):
    """
    Document ê°ì²´ì— í•´ë‹¹í•˜ëŠ” ë²¡í„°ë“¤ì„ ChromaDBì—ì„œ ì‚­ì œ
    """
    try:
        project_id = str(document_obj.project.id)
        document_id = str(document_obj.id)
        collection_name = f"project_{project_id}"
        
        collection = chroma_client.get_collection(name=collection_name)
        
        # [í•µì‹¬] document_id ë©”íƒ€ë°ì´í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ëª¨ë“  ë²¡í„° ì‚­ì œ
        collection.delete(
            where={"document_id": document_id}
        )
        print(f"âœ… [Project: {project_id}, Doc: {document_id}] ë²¡í„° ì‚­ì œ ì„±ê³µ.")
        return True

    except Exception as e:
        print(f"âŒ [Project: {project_id}, Doc: {document_id}] ë²¡í„° ì‚­ì œ ì‹¤íŒ¨: {e}")
        return False
    
def get_rag_answer(project_id, query):
    """
    íŠ¹ì • í”„ë¡œì íŠ¸ì˜ RAG ì²´ì¸ì„ êµ¬ì„±í•˜ê³  ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.
    ë‹µë³€ê³¼ í•¨ê»˜ ì‚¬ìš©ëœ ì†ŒìŠ¤ ë©”íƒ€ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        collection_name = f"project_{project_id}"

        # 1. LangChainê³¼ ChromaDBë¥¼ ì—°ê²°í•˜ëŠ” VectorStore ê°ì²´ ìƒì„±
        vector_store = Chroma(
            client=chroma_client,
            collection_name=collection_name,
            embedding_function=openai_embeddings,
        )

        # 2. VectorStoreë¥¼ 'Retriever' (ê²€ìƒ‰ê¸°)ë¡œ ë³€í™˜
        retriever = vector_store.as_retriever(search_kwargs={"k": 10})
        
        # 3. ë¬¸ì„œ ê²€ìƒ‰ ë° ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ìˆ˜ë™ ì‹¤í–‰)
        docs = retriever.invoke(query)
        
        # ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…: [ID: doc_id, Page: page_num] Content...
        formatted_context = ""
        sources_metadata = []
        
        for doc in docs:
            doc_id = doc.metadata.get('document_id', 'unknown')
            page_num = doc.metadata.get('source_page', 0) + 1 # 1-based index
            doc_name = doc.metadata.get('name', 'Unknown Document')
            
            formatted_context += f"[Document ID: {doc_id}, Page: {page_num}] {doc.page_content}\n\n"
            
            sources_metadata.append({
                "document_id": doc_id,
                "page": page_num,
                "name": doc_name,
                "content_snippet": doc.page_content[:100] + "..."
            })

        # 4. RAG í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
        template = """
        ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ì—¬ëŸ¬ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ì „ë¬¸ì ì¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
        ì œì‹œëœ [Context] ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œë§Œ ì‚¬ìš©ìì˜ [Question]ì— ë‹µë³€í•˜ì„¸ìš”.
        
        [Context]ì˜ ê° ë¶€ë¶„ì€ [Document ID: ..., Page: ...] í˜•ì‹ìœ¼ë¡œ ì¶œì²˜ê°€ í‘œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.
        ë‹µë³€ì„ ì‘ì„±í•  ë•Œ, ê° ë¬¸ì¥ì´ë‚˜ ë‹¨ë½ì˜ ëì— í•´ë‹¹ ì •ë³´ì˜ ì¶œì²˜(Document IDì™€ Page)ë¥¼ ë°˜ë“œì‹œ ëª…ì‹œí•˜ì„¸ìš”.
        í˜•ì‹ ì˜ˆì‹œ: "ì´ ë‚´ìš©ì€ ë¬¸ì„œì˜ í•µì‹¬ì…ë‹ˆë‹¤. [Document ID: 123, Page: 5]"
        
        [Context]ì— ì—†ëŠ” ë‚´ìš©ì€ ë‹µë³€í•  ìˆ˜ ì—†ë‹¤ê³  ì†”ì§í•˜ê²Œ ë§í•˜ì„¸ìš”.
        í•­ìƒ í•œê¸€ë¡œ ëŒ€ë‹µí•˜ê³ , "Contextì— ë”°ë¥´ë©´"ê³¼ ê°™ì€ ë§ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
        
        ë‹µë³€ ì‘ì„± ì‹œ ë§ˆí¬ë‹¤ìš´ ê·œì¹™:
        - ì œëª©ì€ H3(###) ì´í•˜ë§Œ ì‚¬ìš©í•˜ì„¸ìš” (H1(#), H2(##) ì‚¬ìš© ê¸ˆì§€)
        - ë¦¬ìŠ¤íŠ¸, ë³¼ë“œì²´, ì½”ë“œ ë¸”ë¡ ë“± ë‹¤ë¥¸ ë§ˆí¬ë‹¤ìš´ ìš”ì†ŒëŠ” ììœ ë¡­ê²Œ ì‚¬ìš©í•˜ì„¸ìš”

        [Context]:
        {context}

        [Question]:
        {query}

        [Answer]:
        """
        prompt = ChatPromptTemplate.from_template(template)

        # 5. ì²´ì¸ ì‹¤í–‰ (LLM í˜¸ì¶œ)
        chain = prompt | llm | StrOutputParser()
        answer = chain.invoke({"context": formatted_context, "query": query})
        
        return {
            "answer": answer,
            "sources": sources_metadata
        }

    except Exception as e:
        print(f"âŒ [Project: {project_id}] RAG ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
        return {
            "answer": "ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ IDë¥¼ í™•ì¸í•˜ê±°ë‚˜, ë¬¸ì„œë¥¼ ì—…ë¡œë“œí–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.",
            "sources": []
        }

def generate_quiz(project_id, num_questions=5):
    """
    í”„ë¡œì íŠ¸ì˜ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í€´ì¦ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        from .models import Project, Quiz, Question
        import json

        # 1. í”„ë¡œì íŠ¸ í™•ì¸
        project = Project.objects.get(id=project_id)
        
        # 2. ChromaDBì—ì„œ ëœë¤í•˜ê²Œ ë¬¸ì„œ ì²­í¬ ê°€ì ¸ì˜¤ê¸° (ë˜ëŠ” ê²€ìƒ‰)
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ 'important concepts'ë¡œ ê²€ìƒ‰í•˜ì—¬ ê´€ë ¨ ë‚´ìš©ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        collection_name = f"project_{project_id}"
        vector_store = Chroma(
            client=chroma_client,
            collection_name=collection_name,
            embedding_function=openai_embeddings,
        )
        
        # í€´ì¦ˆ ìƒì„±ì„ ìœ„í•œ í¬ê´„ì ì¸ ê²€ìƒ‰ ì¿¼ë¦¬
        retriever = vector_store.as_retriever(search_kwargs={"k": 15}) # ì¶©ë¶„í•œ ì»¨í…ìŠ¤íŠ¸ í™•ë³´
        docs = retriever.invoke("important key concepts and definitions summary")
        
        context = "\n\n".join([doc.page_content for doc in docs])
        
        if not context:
            return None

        # 3. LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„± (JSON ì¶œë ¥ ê°•ì œ)
        template = """
        You are a professional quiz generator.
        Based on the following [Context], generate {num_questions} multiple-choice questions.
        The questions should be in Korean.
        
        [Context]:
        {context}
        
        Output Format (JSON Array):
        [
            {{
                "question_text": "ì§ˆë¬¸ ë‚´ìš©",
                "options": ["ë³´ê¸°1", "ë³´ê¸°2", "ë³´ê¸°3", "ë³´ê¸°4"],
                "answer": "ì •ë‹µ (ë³´ê¸° ì¤‘ í•˜ë‚˜ì™€ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•¨)"
            }},
            ...
        ]
        
        Ensure the output is a valid JSON array. Do not include any markdown formatting (like ```json).
        """
        
        prompt = ChatPromptTemplate.from_template(template)
        
        chain = (
            prompt 
            | llm 
            | StrOutputParser()
        )
        
        # 4. ìƒì„± ì‹¤í–‰
        json_response = chain.invoke({"context": context, "num_questions": num_questions})
        
        # 5. JSON íŒŒì‹± ë° DB ì €ì¥
        # ê°€ë” LLMì´ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì„ í¬í•¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì œê±° ì‹œë„
        cleaned_json = json_response.replace("```json", "").replace("```", "").strip()
        questions_data = json.loads(cleaned_json)
        
        # í€´ì¦ˆ ê°ì²´ ìƒì„±
        quiz = Quiz.objects.create(
            project=project,
            title=f"Generated Quiz ({len(questions_data)} Questions)"
        )
        
        # ë¬¸ì œ ê°ì²´ ìƒì„±
        for q_data in questions_data:
            Question.objects.create(
                quiz=quiz,
                question_text=q_data['question_text'],
                options=q_data['options'],
                answer=q_data['answer']
            )
            
        return quiz

    except Exception as e:
        print(f"âŒ [Project: {project_id}] í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: {e}")
        return None